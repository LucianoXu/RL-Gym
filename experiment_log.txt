# very easy to train
# ./main train CartPole-v1 --ckpt=ckpt/CartPole/v1 --init -i 4 -o 2 --arch=rmsmlp --hidden_layers=2 --grad_norm_clip=10.0 --steps=3500 --device=cpu

# Training failed. Because the reward signal is never reached and the model is not trained in REINFORCE.
# ./main train MountainCar-v0 --ckpt=ckpt/MountainCar/v1 --init -i 2 -o 3 --arch=rmsmlp --hidden_layers=2 --grad_norm_clip=10.0 --steps=3500 --save_interval=30 --device=cpu

# saturate at -80 total reward. should be optimal
# ./main train Acrobot-v1 --ckpt=ckpt/Acrobot/v1 --init -i 6 -o 3 --arch=rmsmlp --hidden_layers=2 --grad_norm_clip=10.0 --steps=3500 --save_interval=30 --device=cpu

# same as above
# ./main train Acrobot-v1 --ckpt=ckpt/Acrobot/v2 --init -i 6 -o 3 --arch=rmsmlp --hidden_layers=3 --grad_norm_clip=100.0 --steps=3500 --save_interval=30 --device=cpu

#--------------------------------------------------

# successful training
# ./main train LunarLander-v3 a0 --ckpt=ckpt/lunarlanding/a0-v1 --init --grad_norm_clip=10.0 --steps=3500 --save_interval=30

# previous training loss recovered
# ./main train LunarLander-v3 a1 --ckpt=ckpt/lunarlanding/a1-v1 --init --grad_norm_clip=0.1 --steps=3500 --save_interval=30

# demonstration success
# ./main testM LunarLander-v3 a1 --ckpt=ckpt/lunarlanding/a1-v1/model_final.pth