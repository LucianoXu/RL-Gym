# very easy to train
# ./main train CartPole-v1 --ckpt=ckpt/CartPole/v1 --init -i 4 -o 2 --arch=rmsmlp --hidden_layers=2 --grad_norm_clip=10.0 --steps=3500 --device=cpu

# Training failed. Because the reward signal is never reached and the model is not trained in REINFORCE.
# ./main train MountainCar-v0 --ckpt=ckpt/MountainCar/v1 --init -i 2 -o 3 --arch=rmsmlp --hidden_layers=2 --grad_norm_clip=10.0 --steps=3500 --save_interval=30 --device=cpu

# saturate at -80 total reward. should be optimal
# ./main train Acrobot-v1 --ckpt=ckpt/Acrobot/v1 --init -i 6 -o 3 --arch=rmsmlp --hidden_layers=2 --grad_norm_clip=10.0 --steps=3500 --save_interval=30 --device=cpu

# same as above
# ./main train Acrobot-v1 --ckpt=ckpt/Acrobot/v2 --init -i 6 -o 3 --arch=rmsmlp --hidden_layers=3 --grad_norm_clip=100.0 --steps=3500 --save_interval=30 --device=cpu

#--------------------------------------------------

# successful training
# ./main train LunarLander-v3 a0 --ckpt=ckpt/lunarlanding/a0-v1 --init --grad_norm_clip=10.0 --steps=3500 --save_interval=30

# previous training loss recovered
# ./main train LunarLander-v3 a1 --ckpt=ckpt/lunarlanding/a1-v1 --init --grad_norm_clip=0.1 --steps=3500 --save_interval=30

# demonstration success
# ./main testM LunarLander-v3 a1 --ckpt=ckpt/lunarlanding/a1-v1/model_final.pth

# previous training loss recovered. usage of LeakyReLU makes learning slower
# ./main train CartPole-v1 a0 --ckpt=ckpt/CartPole/a1-v0 --init --grad_norm_clip=10.0 --steps=3500 --save_interval=30


# training failed. could be implementation issue.
# ./main train Pendulum-v1 a0 --ckpt=ckpt/Pendulum/a0-v0 --init --grad_norm_clip=10.0 --steps=3500 --save_interval=30


# use sigmoid instead of ReLU for std. training was successful, but very unstable
# ./main train Pendulum-v1 a0 --ckpt=ckpt/Pendulum/a0-v1 --init --grad_norm_clip=10.0 --steps=3500 --save_interval=30

# using deeper network. reaching -200 reward, which should be optimal. But training is much more unstable.
# ./main train Pendulum-v1 a1 --ckpt=ckpt/Pendulum/a1-v0 --init --grad_norm_clip=10.0 --steps=3500 --save_interval=30

# using smaller grad_norm_clip and larger batch size. stability improved but still a large problem. Maybe PPO can help.
# ./main train Pendulum-v1 a1 --ckpt=ckpt/Pendulum/a1-v1 --init --grad_norm_clip=1.0 --steps=3500 --bs=256 --save_interval=30